{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685a4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd8afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e188eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9b861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Adj Close'] /= 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a113f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>MFV</th>\n",
       "      <th>40 period ADX.</th>\n",
       "      <th>AO</th>\n",
       "      <th>UPPER</th>\n",
       "      <th>LOWER</th>\n",
       "      <th>40 period ATR</th>\n",
       "      <th>Buy.</th>\n",
       "      <th>Sell.</th>\n",
       "      <th>Buy..1</th>\n",
       "      <th>...</th>\n",
       "      <th>SIGNAL.3</th>\n",
       "      <th>VZO</th>\n",
       "      <th>40 Williams %R</th>\n",
       "      <th>40 period WMA.</th>\n",
       "      <th>WOBV</th>\n",
       "      <th>WT1.</th>\n",
       "      <th>WT2.</th>\n",
       "      <th>40 period ZLEMA</th>\n",
       "      <th>pct</th>\n",
       "      <th>pct_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164075</td>\n",
       "      <td>2.116714e+07</td>\n",
       "      <td>14.309929</td>\n",
       "      <td>0.182759</td>\n",
       "      <td>16.689889</td>\n",
       "      <td>16.054189</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>0.497433</td>\n",
       "      <td>1.605319</td>\n",
       "      <td>1.443633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039537</td>\n",
       "      <td>12.117903</td>\n",
       "      <td>-33.487389</td>\n",
       "      <td>16.251470</td>\n",
       "      <td>9.670663e+06</td>\n",
       "      <td>20.127102</td>\n",
       "      <td>18.448995</td>\n",
       "      <td>16.353788</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>0.027954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162600</td>\n",
       "      <td>1.943094e+07</td>\n",
       "      <td>14.140038</td>\n",
       "      <td>0.171225</td>\n",
       "      <td>16.685534</td>\n",
       "      <td>16.049697</td>\n",
       "      <td>0.154255</td>\n",
       "      <td>0.114767</td>\n",
       "      <td>1.950409</td>\n",
       "      <td>1.317071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>7.085278</td>\n",
       "      <td>-45.734591</td>\n",
       "      <td>16.251063</td>\n",
       "      <td>9.382564e+06</td>\n",
       "      <td>15.500417</td>\n",
       "      <td>18.108371</td>\n",
       "      <td>16.356737</td>\n",
       "      <td>0.031090</td>\n",
       "      <td>0.034847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161940</td>\n",
       "      <td>1.931478e+07</td>\n",
       "      <td>14.107290</td>\n",
       "      <td>0.141156</td>\n",
       "      <td>16.674920</td>\n",
       "      <td>16.039176</td>\n",
       "      <td>0.155231</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.801172</td>\n",
       "      <td>1.259344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>2.478898</td>\n",
       "      <td>-51.990512</td>\n",
       "      <td>16.247949</td>\n",
       "      <td>9.259769e+06</td>\n",
       "      <td>6.009721</td>\n",
       "      <td>14.930795</td>\n",
       "      <td>16.351900</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.031090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159384</td>\n",
       "      <td>1.926717e+07</td>\n",
       "      <td>14.454950</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>16.642213</td>\n",
       "      <td>16.003133</td>\n",
       "      <td>0.165355</td>\n",
       "      <td>4.036733</td>\n",
       "      <td>4.127643</td>\n",
       "      <td>1.523862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031022</td>\n",
       "      <td>-4.524090</td>\n",
       "      <td>-74.593351</td>\n",
       "      <td>16.232945</td>\n",
       "      <td>8.488516e+06</td>\n",
       "      <td>-8.516856</td>\n",
       "      <td>8.280096</td>\n",
       "      <td>16.319218</td>\n",
       "      <td>-0.003202</td>\n",
       "      <td>0.018428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160025</td>\n",
       "      <td>2.152113e+07</td>\n",
       "      <td>14.790423</td>\n",
       "      <td>-0.025260</td>\n",
       "      <td>16.618224</td>\n",
       "      <td>15.975358</td>\n",
       "      <td>0.166168</td>\n",
       "      <td>2.714474</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>1.637256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019899</td>\n",
       "      <td>1.134482</td>\n",
       "      <td>-67.875707</td>\n",
       "      <td>16.221917</td>\n",
       "      <td>8.642566e+06</td>\n",
       "      <td>-17.888593</td>\n",
       "      <td>-1.223828</td>\n",
       "      <td>16.288813</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>-0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>0.262242</td>\n",
       "      <td>1.880111e+09</td>\n",
       "      <td>9.812695</td>\n",
       "      <td>1.413848</td>\n",
       "      <td>27.789974</td>\n",
       "      <td>25.379094</td>\n",
       "      <td>0.625518</td>\n",
       "      <td>0.047638</td>\n",
       "      <td>1.999721</td>\n",
       "      <td>0.761950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379889</td>\n",
       "      <td>3.274067</td>\n",
       "      <td>-40.543403</td>\n",
       "      <td>26.172074</td>\n",
       "      <td>-1.728923e+09</td>\n",
       "      <td>29.793987</td>\n",
       "      <td>38.323516</td>\n",
       "      <td>26.696761</td>\n",
       "      <td>0.026187</td>\n",
       "      <td>0.034805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>0.261323</td>\n",
       "      <td>1.887916e+09</td>\n",
       "      <td>9.714401</td>\n",
       "      <td>1.108465</td>\n",
       "      <td>27.757073</td>\n",
       "      <td>25.354991</td>\n",
       "      <td>0.624268</td>\n",
       "      <td>0.777759</td>\n",
       "      <td>0.289856</td>\n",
       "      <td>0.763455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371549</td>\n",
       "      <td>-0.359609</td>\n",
       "      <td>-42.641574</td>\n",
       "      <td>26.178577</td>\n",
       "      <td>-1.730396e+09</td>\n",
       "      <td>20.280532</td>\n",
       "      <td>32.902688</td>\n",
       "      <td>26.747173</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>0.026187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>0.273000</td>\n",
       "      <td>1.922189e+09</td>\n",
       "      <td>9.540777</td>\n",
       "      <td>0.920966</td>\n",
       "      <td>27.837765</td>\n",
       "      <td>25.442989</td>\n",
       "      <td>0.646010</td>\n",
       "      <td>3.598507</td>\n",
       "      <td>0.419452</td>\n",
       "      <td>1.033460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373455</td>\n",
       "      <td>8.465253</td>\n",
       "      <td>-15.981756</td>\n",
       "      <td>26.242405</td>\n",
       "      <td>-1.681632e+09</td>\n",
       "      <td>21.667353</td>\n",
       "      <td>27.516576</td>\n",
       "      <td>26.909262</td>\n",
       "      <td>0.056297</td>\n",
       "      <td>0.018803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0.278350</td>\n",
       "      <td>1.942090e+09</td>\n",
       "      <td>9.463689</td>\n",
       "      <td>0.853935</td>\n",
       "      <td>27.963513</td>\n",
       "      <td>25.574860</td>\n",
       "      <td>0.649760</td>\n",
       "      <td>1.923350</td>\n",
       "      <td>0.228977</td>\n",
       "      <td>1.118212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384875</td>\n",
       "      <td>13.074673</td>\n",
       "      <td>-3.767145</td>\n",
       "      <td>26.331183</td>\n",
       "      <td>-1.668816e+09</td>\n",
       "      <td>26.838390</td>\n",
       "      <td>24.645066</td>\n",
       "      <td>27.099390</td>\n",
       "      <td>0.066091</td>\n",
       "      <td>0.056297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>0.279529</td>\n",
       "      <td>1.952979e+09</td>\n",
       "      <td>9.407359</td>\n",
       "      <td>0.961229</td>\n",
       "      <td>28.089541</td>\n",
       "      <td>25.709446</td>\n",
       "      <td>0.646260</td>\n",
       "      <td>0.530155</td>\n",
       "      <td>0.141865</td>\n",
       "      <td>1.062206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400570</td>\n",
       "      <td>16.116428</td>\n",
       "      <td>-1.075344</td>\n",
       "      <td>26.424316</td>\n",
       "      <td>-1.666881e+09</td>\n",
       "      <td>31.856477</td>\n",
       "      <td>25.160688</td>\n",
       "      <td>27.261605</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>0.066091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Adj Close           MFV  40 period ADX.        AO      UPPER      LOWER  \\\n",
       "0      0.164075  2.116714e+07       14.309929  0.182759  16.689889  16.054189   \n",
       "1      0.162600  1.943094e+07       14.140038  0.171225  16.685534  16.049697   \n",
       "2      0.161940  1.931478e+07       14.107290  0.141156  16.674920  16.039176   \n",
       "3      0.159384  1.926717e+07       14.454950  0.058470  16.642213  16.003133   \n",
       "4      0.160025  2.152113e+07       14.790423 -0.025260  16.618224  15.975358   \n",
       "...         ...           ...             ...       ...        ...        ...   \n",
       "4954   0.262242  1.880111e+09        9.812695  1.413848  27.789974  25.379094   \n",
       "4955   0.261323  1.887916e+09        9.714401  1.108465  27.757073  25.354991   \n",
       "4956   0.273000  1.922189e+09        9.540777  0.920966  27.837765  25.442989   \n",
       "4957   0.278350  1.942090e+09        9.463689  0.853935  27.963513  25.574860   \n",
       "4958   0.279529  1.952979e+09        9.407359  0.961229  28.089541  25.709446   \n",
       "\n",
       "      40 period ATR      Buy.     Sell.    Buy..1  ...  SIGNAL.3        VZO  \\\n",
       "0          0.153630  0.497433  1.605319  1.443633  ...  0.039537  12.117903   \n",
       "1          0.154255  0.114767  1.950409  1.317071  ...  0.041372   7.085278   \n",
       "2          0.155231  0.710949  0.801172  1.259344  ...  0.040254   2.478898   \n",
       "3          0.165355  4.036733  4.127643  1.523862  ...  0.031022  -4.524090   \n",
       "4          0.166168  2.714474  0.098184  1.637256  ...  0.019899   1.134482   \n",
       "...             ...       ...       ...       ...  ...       ...        ...   \n",
       "4954       0.625518  0.047638  1.999721  0.761950  ...  0.379889   3.274067   \n",
       "4955       0.624268  0.777759  0.289856  0.763455  ...  0.371549  -0.359609   \n",
       "4956       0.646010  3.598507  0.419452  1.033460  ...  0.373455   8.465253   \n",
       "4957       0.649760  1.923350  0.228977  1.118212  ...  0.384875  13.074673   \n",
       "4958       0.646260  0.530155  0.141865  1.062206  ...  0.400570  16.116428   \n",
       "\n",
       "      40 Williams %R  40 period WMA.          WOBV       WT1.       WT2.  \\\n",
       "0         -33.487389       16.251470  9.670663e+06  20.127102  18.448995   \n",
       "1         -45.734591       16.251063  9.382564e+06  15.500417  18.108371   \n",
       "2         -51.990512       16.247949  9.259769e+06   6.009721  14.930795   \n",
       "3         -74.593351       16.232945  8.488516e+06  -8.516856   8.280096   \n",
       "4         -67.875707       16.221917  8.642566e+06 -17.888593  -1.223828   \n",
       "...              ...             ...           ...        ...        ...   \n",
       "4954      -40.543403       26.172074 -1.728923e+09  29.793987  38.323516   \n",
       "4955      -42.641574       26.178577 -1.730396e+09  20.280532  32.902688   \n",
       "4956      -15.981756       26.242405 -1.681632e+09  21.667353  27.516576   \n",
       "4957       -3.767145       26.331183 -1.668816e+09  26.838390  24.645066   \n",
       "4958       -1.075344       26.424316 -1.666881e+09  31.856477  25.160688   \n",
       "\n",
       "      40 period ZLEMA       pct  pct_shifted  \n",
       "0           16.353788  0.034847     0.027954  \n",
       "1           16.356737  0.031090     0.034847  \n",
       "2           16.351900  0.018428     0.031090  \n",
       "3           16.319218 -0.003202     0.018428  \n",
       "4           16.288813  0.022687    -0.003202  \n",
       "...               ...       ...          ...  \n",
       "4954        26.696761  0.026187     0.034805  \n",
       "4955        26.747173  0.018803     0.026187  \n",
       "4956        26.909262  0.056297     0.018803  \n",
       "4957        27.099390  0.066091     0.056297  \n",
       "4958        27.261605  0.050490     0.066091  \n",
       "\n",
       "[4959 rows x 118 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5720f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e9a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TimeSeries.from_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb0e8b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "653b17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.split_before(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3653262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;TimeSeries (DataArray) (time: 3718, component: 118, sample: 1)&gt;\n",
       "array([[[1.64074993e-01],\n",
       "        [2.11671375e+07],\n",
       "        [1.43099289e+01],\n",
       "        ...,\n",
       "        [1.63537877e+01],\n",
       "        [3.48470380e-02],\n",
       "        [2.79538430e-02]],\n",
       "\n",
       "       [[1.62600002e-01],\n",
       "        [1.94309448e+07],\n",
       "        [1.41400377e+01],\n",
       "        ...,\n",
       "        [1.63567366e+01],\n",
       "        [3.10896600e-02],\n",
       "        [3.48470380e-02]],\n",
       "\n",
       "       [[1.61940002e-01],\n",
       "        [1.93147831e+07],\n",
       "        [1.41072896e+01],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [7.75075929e+01],\n",
       "        [9.07753104e-02],\n",
       "        [9.19944872e-02]],\n",
       "\n",
       "       [[7.75660477e-01],\n",
       "        [1.63409422e+09],\n",
       "        [2.02250059e+01],\n",
       "        ...,\n",
       "        [7.76463491e+01],\n",
       "        [8.53711837e-02],\n",
       "        [9.07753104e-02]],\n",
       "\n",
       "       [[7.71399994e-01],\n",
       "        [1.63281299e+09],\n",
       "        [2.02252986e+01],\n",
       "        ...,\n",
       "        [7.77762832e+01],\n",
       "        [7.16865211e-02],\n",
       "        [8.53711837e-02]]])\n",
       "Coordinates:\n",
       "  * time       (time) int64 0 1 2 3 4 5 6 ... 3711 3712 3713 3714 3715 3716 3717\n",
       "  * component  (component) object &#x27;Adj Close&#x27; &#x27;MFV&#x27; ... &#x27;pct&#x27; &#x27;pct_shifted&#x27;\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>TimeSeries (DataArray)</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 3718</li><li><span class='xr-has-index'>component</span>: 118</li><li><span>sample</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-6ba5fce6-c207-4e33-a63e-7f9da18cfba9' class='xr-array-in' type='checkbox' checked><label for='section-6ba5fce6-c207-4e33-a63e-7f9da18cfba9' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.1641 2.117e+07 14.31 0.1828 16.69 ... 59.07 77.78 0.07169 0.08537</span></div><div class='xr-array-data'><pre>array([[[1.64074993e-01],\n",
       "        [2.11671375e+07],\n",
       "        [1.43099289e+01],\n",
       "        ...,\n",
       "        [1.63537877e+01],\n",
       "        [3.48470380e-02],\n",
       "        [2.79538430e-02]],\n",
       "\n",
       "       [[1.62600002e-01],\n",
       "        [1.94309448e+07],\n",
       "        [1.41400377e+01],\n",
       "        ...,\n",
       "        [1.63567366e+01],\n",
       "        [3.10896600e-02],\n",
       "        [3.48470380e-02]],\n",
       "\n",
       "       [[1.61940002e-01],\n",
       "        [1.93147831e+07],\n",
       "        [1.41072896e+01],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [7.75075929e+01],\n",
       "        [9.07753104e-02],\n",
       "        [9.19944872e-02]],\n",
       "\n",
       "       [[7.75660477e-01],\n",
       "        [1.63409422e+09],\n",
       "        [2.02250059e+01],\n",
       "        ...,\n",
       "        [7.76463491e+01],\n",
       "        [8.53711837e-02],\n",
       "        [9.07753104e-02]],\n",
       "\n",
       "       [[7.71399994e-01],\n",
       "        [1.63281299e+09],\n",
       "        [2.02252986e+01],\n",
       "        ...,\n",
       "        [7.77762832e+01],\n",
       "        [7.16865211e-02],\n",
       "        [8.53711837e-02]]])</pre></div></div></li><li class='xr-section-item'><input id='section-1554ffaf-6222-43cd-a849-ad7c484f7a4d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1554ffaf-6222-43cd-a849-ad7c484f7a4d' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 ... 3714 3715 3716 3717</div><input id='attrs-0a78710d-ceac-4ffa-81b6-a9f07f73ec30' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0a78710d-ceac-4ffa-81b6-a9f07f73ec30' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bb9ff273-2a45-4a08-844c-d5319ac7bd1f' class='xr-var-data-in' type='checkbox'><label for='data-bb9ff273-2a45-4a08-844c-d5319ac7bd1f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([   0,    1,    2, ..., 3715, 3716, 3717], dtype=int64)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>component</span></div><div class='xr-var-dims'>(component)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;Adj Close&#x27; &#x27;MFV&#x27; ... &#x27;pct_shifted&#x27;</div><input id='attrs-9abe7868-b01a-4631-8ce6-556044bf8e9e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9abe7868-b01a-4631-8ce6-556044bf8e9e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-90e22297-6ece-421a-8201-bfe5c2f61bf5' class='xr-var-data-in' type='checkbox'><label for='data-90e22297-6ece-421a-8201-bfe5c2f61bf5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;Adj Close&#x27;, &#x27;MFV&#x27;, &#x27;40 period ADX.&#x27;, &#x27;AO&#x27;, &#x27;UPPER&#x27;, &#x27;LOWER&#x27;,\n",
       "       &#x27;40 period ATR&#x27;, &#x27;Buy.&#x27;, &#x27;Sell.&#x27;, &#x27;Buy..1&#x27;, &#x27;Sell..1&#x27;, &#x27;BB_UPPER&#x27;,\n",
       "       &#x27;BB_MIDDLE&#x27;, &#x27;BB_LOWER&#x27;, &#x27;40 period BBWITH&#x27;, &#x27;Balance Of Power&#x27;,\n",
       "       &#x27;40 period CCI&#x27;, &#x27;CFI&#x27;, &#x27;MFV.1&#x27;, &#x27;Short.&#x27;, &#x27;Long.&#x27;, &#x27;CMO&#x27;,\n",
       "       &#x27;Coppock Curve&#x27;, &#x27;40 period DEMA&#x27;, &#x27;DI+&#x27;, &#x27;DI-&#x27;, &#x27;LOWER.1&#x27;, &#x27;MIDDLE&#x27;,\n",
       "       &#x27;UPPER.1&#x27;, &#x27;Bull.&#x27;, &#x27;Bear.&#x27;, &#x27;40 period Force Index&#x27;, &#x27;40 period EMA&#x27;,\n",
       "       &#x27;40 period ER&#x27;, &#x27;10 period EVSTC&#x27;, &#x27;40 period EVWMA.&#x27;, &#x27;MACD&#x27;, &#x27;SIGNAL&#x27;,\n",
       "       &#x27;40 period FISH.&#x27;, &#x27;40 period FRAMA.&#x27;, &#x27;0&#x27;, &#x27;40 period HMA.&#x27;, &#x27;TENKAN&#x27;,\n",
       "       &#x27;KIJUN&#x27;, &#x27;CHIKOU&#x27;, &#x27;IFT_RSI&#x27;, &#x27;40 period KAMA.&#x27;, &#x27;KC_UPPER&#x27;, &#x27;KC_LOWER&#x27;,\n",
       "       &#x27;KST&#x27;, &#x27;MACD.1&#x27;, &#x27;SIGNAL.1&#x27;, &#x27;40 period MFI&#x27;, &#x27;Mass Index&#x27;,\n",
       "       &#x27;BB_UPPER.1&#x27;, &#x27;BB_MIDDLE.1&#x27;, &#x27;BB_LOWER.1&#x27;, &#x27;MOM&#x27;, &#x27;MSD&#x27;, &#x27;OBV&#x27;, &#x27;%b&#x27;,\n",
       "       &#x27;pivot&#x27;, &#x27;s1&#x27;, &#x27;s2&#x27;, &#x27;s3&#x27;, &#x27;s4&#x27;, &#x27;r1&#x27;, &#x27;r2&#x27;, &#x27;r3&#x27;, &#x27;r4&#x27;, &#x27;pivot.1&#x27;,\n",
       "       &#x27;s1.1&#x27;, &#x27;s2.1&#x27;, &#x27;s3.1&#x27;, &#x27;s4.1&#x27;, &#x27;r1.1&#x27;, &#x27;r2.1&#x27;, &#x27;r3.1&#x27;, &#x27;r4.1&#x27;, &#x27;PPO&#x27;,\n",
       "       &#x27;SIGNAL.2&#x27;, &#x27;HISTO&#x27;, &#x27;psar&#x27;, &#x27;40 period PZO&#x27;, &#x27;ROC&#x27;, &#x27;40 period RSI&#x27;,\n",
       "       &#x27;0.1&#x27;, &#x27;40 period SMA&#x27;, &#x27;40 period SMM&#x27;, &#x27;SMMA&#x27;, &#x27;40 period SQZMI&#x27;,\n",
       "       &#x27;40 period SSMA&#x27;, &#x27;10 period STC&#x27;, &#x27;40 period STOCH %K&#x27;,\n",
       "       &#x27;14 period stochastic RSI.&#x27;, &#x27;40 period TEMA&#x27;, &#x27;TP&#x27;, &#x27;TR&#x27;,\n",
       "       &#x27;40 period TRIX&#x27;, &#x27;TSI&#x27;, &#x27;0.2&#x27;, &#x27;VBM&#x27;, &#x27;VFI&#x27;, &#x27;VIm&#x27;, &#x27;VIp&#x27;, &#x27;VPT&#x27;,\n",
       "       &#x27;VWAP.&#x27;, &#x27;MACD.2&#x27;, &#x27;SIGNAL.3&#x27;, &#x27;VZO&#x27;, &#x27;40 Williams %R&#x27;,\n",
       "       &#x27;40 period WMA.&#x27;, &#x27;WOBV&#x27;, &#x27;WT1.&#x27;, &#x27;WT2.&#x27;, &#x27;40 period ZLEMA&#x27;, &#x27;pct&#x27;,\n",
       "       &#x27;pct_shifted&#x27;], dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b9d6ff74-cc39-4ecf-84e6-283a5268a14f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b9d6ff74-cc39-4ecf-84e6-283a5268a14f' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>static_covariates :</span></dt><dd>None</dd><dt><span>hierarchy :</span></dt><dd>None</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<TimeSeries (DataArray) (time: 3718, component: 118, sample: 1)>\n",
       "array([[[1.64074993e-01],\n",
       "        [2.11671375e+07],\n",
       "        [1.43099289e+01],\n",
       "        ...,\n",
       "        [1.63537877e+01],\n",
       "        [3.48470380e-02],\n",
       "        [2.79538430e-02]],\n",
       "\n",
       "       [[1.62600002e-01],\n",
       "        [1.94309448e+07],\n",
       "        [1.41400377e+01],\n",
       "        ...,\n",
       "        [1.63567366e+01],\n",
       "        [3.10896600e-02],\n",
       "        [3.48470380e-02]],\n",
       "\n",
       "       [[1.61940002e-01],\n",
       "        [1.93147831e+07],\n",
       "        [1.41072896e+01],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [7.75075929e+01],\n",
       "        [9.07753104e-02],\n",
       "        [9.19944872e-02]],\n",
       "\n",
       "       [[7.75660477e-01],\n",
       "        [1.63409422e+09],\n",
       "        [2.02250059e+01],\n",
       "        ...,\n",
       "        [7.76463491e+01],\n",
       "        [8.53711837e-02],\n",
       "        [9.07753104e-02]],\n",
       "\n",
       "       [[7.71399994e-01],\n",
       "        [1.63281299e+09],\n",
       "        [2.02252986e+01],\n",
       "        ...,\n",
       "        [7.77762832e+01],\n",
       "        [7.16865211e-02],\n",
       "        [8.53711837e-02]]])\n",
       "Coordinates:\n",
       "  * time       (time) int64 0 1 2 3 4 5 6 ... 3711 3712 3713 3714 3715 3716 3717\n",
       "  * component  (component) object 'Adj Close' 'MFV' ... 'pct' 'pct_shifted'\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7600436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 16:28:29 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 3658 samples.\n",
      "2022-07-25 16:28:30 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "2022-07-25 16:28:30 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "2022-07-25 16:28:30 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "2022-07-25 16:28:30 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "2022-07-25 16:28:30 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "2022-07-25 16:28:30 pytorch_lightning.callbacks.model_summary INFO: \n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | stacks        | ModuleList       | 61.7 M\n",
      "---------------------------------------------------\n",
      "61.6 M    Trainable params\n",
      "43.8 K    Non-trainable params\n",
      "61.7 M    Total params\n",
      "493.409   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  33%|██████████▌                     | 38/115 [01:38<03:18,  2.58s/it, loss=7.28e+12, train_loss=5.54e+12]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1812480 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NBEATSModel\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m NBEATSModel(input_chunk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,output_chunk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mlen\u001b[39m(val))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\utils\\torch.py:112\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[0;32m    111\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decorated(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py:771\u001b[0m, in \u001b[0;36mTorchForecastingModel.fit\u001b[1;34m(self, series, past_covariates, future_covariates, val_series, val_past_covariates, val_future_covariates, trainer, verbose, epochs, max_samples_per_ts, num_loader_workers)\u001b[0m\n\u001b[0;32m    767\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    769\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain dataset contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_from_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_loader_workers\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\utils\\torch.py:112\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[0;32m    111\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decorated(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py:913\u001b[0m, in \u001b[0;36mTorchForecastingModel.fit_from_dataset\u001b[1;34m(self, train_dataset, val_dataset, trainer, verbose, epochs, num_loader_workers)\u001b[0m\n\u001b[0;32m    904\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to retrain the model without resuming from a checkpoint. This is currently \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscouraged. Consider setting `save_checkpoints` to `True` and specifying `model_name` at model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`new_epochs` is the sum of (epochs already trained + some additional epochs).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    910\u001b[0m     )\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 913\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py:935\u001b[0m, in \u001b[0;36mTorchForecastingModel._train\u001b[1;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[0;32m    932\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ckpt_path\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[0;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    810\u001b[0m )\n\u001b[1;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1236\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1238\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1353\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1353\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:266\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(\n\u001b[0;32m    263\u001b[0m     dataloader, batch_to_device\u001b[38;5;241m=\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_to_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataloader_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    264\u001b[0m )\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:208\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 208\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\batch\\training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m     87\u001b[0m     optimizers \u001b[38;5;241m=\u001b[39m _get_active_optimizers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizer_frequencies, batch_idx)\n\u001b[1;32m---> 88\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_loop\u001b[38;5;241m.\u001b[39mrun(split_batch, batch_idx)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:203\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[1;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvance\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_progress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;66;03m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;66;03m# would be skipped otherwise\u001b[39;00m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_idx] \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39masdict()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:256\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[1;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[0;32m    249\u001b[0m         closure()\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:369\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_tpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTPUAccelerator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_native_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamp_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAMPType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNATIVE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_lbfgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_lbfgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1595\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1592\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1595\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:1646\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1566\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1573\u001b[0m     using_lbfgs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;124;03m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;124;03m    each optimizer.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1644\u001b[0m \n\u001b[0;32m   1645\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1646\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:168\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_idx, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:193\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"Performs the actual optimizer step.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(model, optimizer, opt_idx, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:155\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m    154\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:100\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 100\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    103\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:140\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m    133\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:148\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:134\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 134\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:427\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[1;34m(self, split_batch, batch_idx, opt_idx)\u001b[0m\n\u001b[0;32m    422\u001b[0m step_kwargs \u001b[38;5;241m=\u001b[39m _build_training_step_kwargs(\n\u001b[0;32m    423\u001b[0m     lightning_module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers, split_batch, batch_idx, opt_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hiddens\n\u001b[0;32m    424\u001b[0m )\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 427\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()\n\u001b[0;32m    430\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, training_step_output)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1765\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:333\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m\"\"\"The actual training step.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.training_step` for more details\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mtrain_step_context():\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\double.py:46\u001b[0m, in \u001b[0;36mLightningDoublePrecisionModule.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mtraining_step(\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;241m*\u001b[39mLightningDoublePrecisionModule\u001b[38;5;241m.\u001b[39m_move_float_tensors_to_double(args),\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mLightningDoublePrecisionModule\u001b[38;5;241m.\u001b[39m_move_float_tensors_to_double(kwargs),\n\u001b[0;32m     49\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\pl_forecasting_module.py:148\u001b[0m, in \u001b[0;36mPLForecastingModule.training_step\u001b[1;34m(self, train_batch, batch_idx)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_batch, batch_idx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124;03m\"\"\"performs the training step\"\"\"\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_produce_train_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m train_batch[\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    151\u001b[0m     ]  \u001b[38;5;66;03m# By convention target is always the last element returned by datasets\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(output, target)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\pl_forecasting_module.py:422\u001b[0m, in \u001b[0;36mPLPastCovariatesModule._produce_train_output\u001b[1;34m(self, input_batch)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Currently all our PastCovariates models require past target and covariates concatenated\u001b[39;00m\n\u001b[0;32m    416\u001b[0m inpt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    417\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcat([past_target, past_covariates], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m past_target,\n\u001b[0;32m    420\u001b[0m     static_covariates,\n\u001b[0;32m    421\u001b[0m )\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\nbeats.py:514\u001b[0m, in \u001b[0;36m_NBEATSModule.forward\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m    504\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    505\u001b[0m     x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    510\u001b[0m )\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stack \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacks_list:\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;66;03m# compute stack output\u001b[39;00m\n\u001b[1;32m--> 514\u001b[0m     stack_residual, stack_forecast \u001b[38;5;241m=\u001b[39m \u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# add stack forecast to final output\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m stack_forecast\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\nbeats.py:351\u001b[0m, in \u001b[0;36m_Stack.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    348\u001b[0m     stack_forecast \u001b[38;5;241m=\u001b[39m stack_forecast \u001b[38;5;241m+\u001b[39m y_hat\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;66;03m# subtract backcast from input to produce residual\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_hat\u001b[49m\n\u001b[0;32m    353\u001b[0m stack_residual \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual, stack_forecast\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1812480 bytes."
     ]
    }
   ],
   "source": [
    "from darts.models import NBEATSModel\n",
    "\n",
    "model = NBEATSModel(input_chunk_length=60,output_chunk_length=1)\n",
    "model.fit(train)\n",
    "prediction = model.predict(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca68e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
